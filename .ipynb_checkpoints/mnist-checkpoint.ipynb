{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'official'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-a07bc53dceb9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m  \u001b[1;31m# pylint: disable=g-bad-import-order\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mofficial\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmnist\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mofficial\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflags\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcore\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mflags_core\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mofficial\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogs\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mhooks_helper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'official'"
     ]
    }
   ],
   "source": [
    "# %load D:/learn_ml/tensorflow_models/official/mnist/mnist.py\n",
    "#  Copyright 2017 The TensorFlow Authors. All Rights Reserved.\n",
    "#\n",
    "#  Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "#  you may not use this file except in compliance with the License.\n",
    "#  You may obtain a copy of the License at\n",
    "#\n",
    "#   http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "#  Unless required by applicable law or agreed to in writing, software\n",
    "#  distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "#  See the License for the specific language governing permissions and\n",
    "#  limitations under the License.\n",
    "\"\"\"Convolutional Neural Network Estimator for MNIST, built with tf.layers.\"\"\"\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "from absl import app as absl_app\n",
    "from absl import flags\n",
    "import tensorflow as tf  # pylint: disable=g-bad-import-order\n",
    "\n",
    "from official.mnist import dataset\n",
    "from official.utils.flags import core as flags_core\n",
    "from official.utils.logs import hooks_helper\n",
    "from official.utils.misc import distribution_utils\n",
    "from official.utils.misc import model_helpers\n",
    "\n",
    "\n",
    "LEARNING_RATE = 1e-4\n",
    "\n",
    "\n",
    "def create_model(data_format):\n",
    "  \"\"\"Model to recognize digits in the MNIST dataset.\n",
    "\n",
    "  Network structure is equivalent to:\n",
    "  https://github.com/tensorflow/tensorflow/blob/r1.5/tensorflow/examples/tutorials/mnist/mnist_deep.py\n",
    "  and\n",
    "  https://github.com/tensorflow/models/blob/master/tutorials/image/mnist/convolutional.py\n",
    "\n",
    "  But uses the tf.keras API.\n",
    "\n",
    "  Args:\n",
    "    data_format: Either 'channels_first' or 'channels_last'. 'channels_first' is\n",
    "      typically faster on GPUs while 'channels_last' is typically faster on\n",
    "      CPUs. See\n",
    "      https://www.tensorflow.org/performance/performance_guide#data_formats\n",
    "\n",
    "  Returns:\n",
    "    A tf.keras.Model.\n",
    "  \"\"\"\n",
    "  if data_format == 'channels_first':\n",
    "    input_shape = [1, 28, 28]\n",
    "  else:\n",
    "    assert data_format == 'channels_last'\n",
    "    input_shape = [28, 28, 1]\n",
    "\n",
    "  l = tf.keras.layers\n",
    "  max_pool = l.MaxPooling2D(\n",
    "      (2, 2), (2, 2), padding='same', data_format=data_format)\n",
    "  # The model consists of a sequential chain of layers, so tf.keras.Sequential\n",
    "  # (a subclass of tf.keras.Model) makes for a compact description.\n",
    "  return tf.keras.Sequential(\n",
    "      [\n",
    "          l.Reshape(\n",
    "              target_shape=input_shape,\n",
    "              input_shape=(28 * 28,)),\n",
    "          l.Conv2D(\n",
    "              32,\n",
    "              5,\n",
    "              padding='same',\n",
    "              data_format=data_format,\n",
    "              activation=tf.nn.relu),\n",
    "          max_pool,\n",
    "          l.Conv2D(\n",
    "              64,\n",
    "              5,\n",
    "              padding='same',\n",
    "              data_format=data_format,\n",
    "              activation=tf.nn.relu),\n",
    "          max_pool,\n",
    "          l.Flatten(),\n",
    "          l.Dense(1024, activation=tf.nn.relu),\n",
    "          l.Dropout(0.4),\n",
    "          l.Dense(10)\n",
    "      ])\n",
    "\n",
    "\n",
    "def define_mnist_flags():\n",
    "  flags_core.define_base()\n",
    "  flags_core.define_image()\n",
    "  flags.adopt_module_key_flags(flags_core)\n",
    "  flags_core.set_defaults(data_dir='/tmp/mnist_data',\n",
    "                          model_dir='/tmp/mnist_model',\n",
    "                          batch_size=100,\n",
    "                          train_epochs=40)\n",
    "\n",
    "\n",
    "def model_fn(features, labels, mode, params):\n",
    "  \"\"\"The model_fn argument for creating an Estimator.\"\"\"\n",
    "  model = create_model(params['data_format'])\n",
    "  image = features\n",
    "  if isinstance(image, dict):\n",
    "    image = features['image']\n",
    "\n",
    "  if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "    logits = model(image, training=False)\n",
    "    predictions = {\n",
    "        'classes': tf.argmax(logits, axis=1),\n",
    "        'probabilities': tf.nn.softmax(logits),\n",
    "    }\n",
    "    return tf.estimator.EstimatorSpec(\n",
    "        mode=tf.estimator.ModeKeys.PREDICT,\n",
    "        predictions=predictions,\n",
    "        export_outputs={\n",
    "            'classify': tf.estimator.export.PredictOutput(predictions)\n",
    "        })\n",
    "  if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=LEARNING_RATE)\n",
    "\n",
    "    # If we are running multi-GPU, we need to wrap the optimizer.\n",
    "    if params.get('multi_gpu'):\n",
    "      optimizer = tf.contrib.estimator.TowerOptimizer(optimizer)\n",
    "\n",
    "    logits = model(image, training=True)\n",
    "    loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\n",
    "    accuracy = tf.metrics.accuracy(\n",
    "        labels=labels, predictions=tf.argmax(logits, axis=1))\n",
    "\n",
    "    # Name tensors to be logged with LoggingTensorHook.\n",
    "    tf.identity(LEARNING_RATE, 'learning_rate')\n",
    "    tf.identity(loss, 'cross_entropy')\n",
    "    tf.identity(accuracy[1], name='train_accuracy')\n",
    "\n",
    "    # Save accuracy scalar to Tensorboard output.\n",
    "    tf.summary.scalar('train_accuracy', accuracy[1])\n",
    "\n",
    "    return tf.estimator.EstimatorSpec(\n",
    "        mode=tf.estimator.ModeKeys.TRAIN,\n",
    "        loss=loss,\n",
    "        train_op=optimizer.minimize(loss, tf.train.get_or_create_global_step()))\n",
    "  if mode == tf.estimator.ModeKeys.EVAL:\n",
    "    logits = model(image, training=False)\n",
    "    loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\n",
    "    return tf.estimator.EstimatorSpec(\n",
    "        mode=tf.estimator.ModeKeys.EVAL,\n",
    "        loss=loss,\n",
    "        eval_metric_ops={\n",
    "            'accuracy':\n",
    "                tf.metrics.accuracy(\n",
    "                    labels=labels, predictions=tf.argmax(logits, axis=1)),\n",
    "        })\n",
    "\n",
    "\n",
    "def run_mnist(flags_obj):\n",
    "  \"\"\"Run MNIST training and eval loop.\n",
    "\n",
    "  Args:\n",
    "    flags_obj: An object containing parsed flag values.\n",
    "  \"\"\"\n",
    "  model_helpers.apply_clean(flags_obj)\n",
    "  model_function = model_fn\n",
    "\n",
    "  # Get number of GPUs as defined by the --num_gpus flags and the number of\n",
    "  # GPUs available on the machine.\n",
    "  num_gpus = flags_core.get_num_gpus(flags_obj)\n",
    "  multi_gpu = num_gpus > 1\n",
    "\n",
    "  if multi_gpu:\n",
    "    # Validate that the batch size can be split into devices.\n",
    "    distribution_utils.per_device_batch_size(flags_obj.batch_size, num_gpus)\n",
    "\n",
    "    # There are two steps required if using multi-GPU: (1) wrap the model_fn,\n",
    "    # and (2) wrap the optimizer. The first happens here, and (2) happens\n",
    "    # in the model_fn itself when the optimizer is defined.\n",
    "    model_function = tf.contrib.estimator.replicate_model_fn(\n",
    "        model_fn, loss_reduction=tf.losses.Reduction.MEAN,\n",
    "        devices=[\"/device:GPU:%d\" % d for d in range(num_gpus)])\n",
    "\n",
    "  data_format = flags_obj.data_format\n",
    "  if data_format is None:\n",
    "    data_format = ('channels_first'\n",
    "                   if tf.test.is_built_with_cuda() else 'channels_last')\n",
    "  mnist_classifier = tf.estimator.Estimator(\n",
    "      model_fn=model_function,\n",
    "      model_dir=flags_obj.model_dir,\n",
    "      params={\n",
    "          'data_format': data_format,\n",
    "          'multi_gpu': multi_gpu\n",
    "      })\n",
    "\n",
    "  # Set up training and evaluation input functions.\n",
    "  def train_input_fn():\n",
    "    \"\"\"Prepare data for training.\"\"\"\n",
    "\n",
    "    # When choosing shuffle buffer sizes, larger sizes result in better\n",
    "    # randomness, while smaller sizes use less memory. MNIST is a small\n",
    "    # enough dataset that we can easily shuffle the full epoch.\n",
    "    ds = dataset.train(flags_obj.data_dir)\n",
    "    ds = ds.cache().shuffle(buffer_size=50000).batch(flags_obj.batch_size)\n",
    "\n",
    "    # Iterate through the dataset a set number (`epochs_between_evals`) of times\n",
    "    # during each training session.\n",
    "    ds = ds.repeat(flags_obj.epochs_between_evals)\n",
    "    return ds\n",
    "\n",
    "  def eval_input_fn():\n",
    "    return dataset.test(flags_obj.data_dir).batch(\n",
    "        flags_obj.batch_size).make_one_shot_iterator().get_next()\n",
    "\n",
    "  # Set up hook that outputs training logs every 100 steps.\n",
    "  train_hooks = hooks_helper.get_train_hooks(\n",
    "      flags_obj.hooks, model_dir=flags_obj.model_dir,\n",
    "      batch_size=flags_obj.batch_size)\n",
    "\n",
    "  # Train and evaluate model.\n",
    "  for _ in range(flags_obj.train_epochs // flags_obj.epochs_between_evals):\n",
    "    mnist_classifier.train(input_fn=train_input_fn, hooks=train_hooks)\n",
    "    eval_results = mnist_classifier.evaluate(input_fn=eval_input_fn)\n",
    "    print('\\nEvaluation results:\\n\\t%s\\n' % eval_results)\n",
    "\n",
    "    if model_helpers.past_stop_threshold(flags_obj.stop_threshold,\n",
    "                                         eval_results['accuracy']):\n",
    "      break\n",
    "\n",
    "  # Export the model\n",
    "  if flags_obj.export_dir is not None:\n",
    "    image = tf.placeholder(tf.float32, [None, 28, 28])\n",
    "    input_fn = tf.estimator.export.build_raw_serving_input_receiver_fn({\n",
    "        'image': image,\n",
    "    })\n",
    "    mnist_classifier.export_savedmodel(flags_obj.export_dir, input_fn)\n",
    "\n",
    "\n",
    "def main(_):\n",
    "  run_mnist(flags.FLAGS)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "  tf.logging.set_verbosity(tf.logging.INFO)\n",
    "  define_mnist_flags()\n",
    "  absl_app.run(main)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
